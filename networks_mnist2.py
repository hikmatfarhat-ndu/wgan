import torch
import torch.nn as nn

# The networks are taken from 
# https://arxiv.org/abs/1511.06434

class Generator(nn.Module):
  '''
  Generator class. Random input of size 100 and a label (from 0 to 9) and 
outputs a flattened image 28x28=784. The objective is to output (conditional) images that are indistinguishable 
  from the real MNIST digits.
  '''

  def __init__(self,z_dim=100,
        out_ch=3,norm_type=None,
        final_activation=None):
    super().__init__()
    self.layer1 = nn.Sequential(nn.Linear(in_features=100, out_features=256),
                                nn.LeakyReLU())
    self.layer2 = nn.Sequential(nn.Linear(in_features=256, out_features=512),
                                nn.LeakyReLU())
    self.layer3 = nn.Sequential(nn.Linear(in_features=512, out_features=1024),
                                nn.LeakyReLU())
    self.output = nn.Sequential(nn.Linear(in_features=1024, out_features=28*28),
                                nn.Tanh())

  def forward(self, x):
    
    x = self.layer1(x)
    x = self.layer2(x)
    x = self.layer3(x)
    x = self.output(x)
    return x

class Discriminator(nn.Module):
  '''
  Discriminator class. The input is a flattened image of size 28x28=784 and a label (0 to 9)
  and outputs the probability of the input being real( from the MNIST dataset) or fake (generated by G)
  '''

  def __init__(self,in_ch=3,norm_type:str="batch",final_activation=None):
    super().__init__()
    self.layer1 = nn.Sequential(nn.Linear(in_features=28*28, out_features=1024),
                                nn.LeakyReLU())
    self.layer2 = nn.Sequential(nn.Linear(in_features=1024, out_features=512),
                                nn.LeakyReLU())
    self.layer3 = nn.Sequential(nn.Linear(in_features=512, out_features=256),
                                nn.LeakyReLU())
    self.output = nn.Sequential(nn.Linear(in_features=256, out_features=1),
                                nn.Sigmoid())
    
  def forward(self, x): 
    x = self.layer1(x)
    x = self.layer2(x)
    x = self.layer3(x)
    x = self.output(x)
    return x

class norm_layer(nn.Module):
    def __init__(self, num_channels,norm_type: str = None):
        super().__init__()
        if norm_type == "BatchNorm2d":
            self.norm = nn.BatchNorm2d(num_channels)
        elif norm_type == "GroupNorm":
            self.norm = nn.GroupNorm(num_channels, num_channels)
        elif norm_type is None:
            self.norm = None
        else:
            raise ValueError(f"Unknown normalization type: {norm_type}")
        #self.norm = getattr(torch.nn,norm_type)
                
    def forward(self, x):
        return x if self.norm is None else self.norm(x)
    

class Reshape(nn.Module):
    def __init__(self, *shape):
        super().__init__()
        self.shape = shape

    def forward(self, x):
        return x.view(*self.shape)